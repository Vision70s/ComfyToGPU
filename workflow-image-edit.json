{
  "input": {
    "workflow": {
      "3": {
        "inputs": {
          "seed": 813415424344425,
          "steps": 20,
          "cfg": 2.5,
          "sampler_name": "euler",
          "scheduler": "simple",
          "denoise": 1,
          "model": [
            "75",
            0
          ],
          "positive": [
            "111",
            0
          ],
          "negative": [
            "110",
            0
          ],
          "latent_image": [
            "88",
            0
          ]
        },
        "class_type": "KSampler",
        "_meta": {
          "title": "KSampler"
        }
      },
      "8": {
        "inputs": {
          "samples": [
            "3",
            0
          ],
          "vae": [
            "39",
            0
          ]
        },
        "class_type": "VAEDecode",
        "_meta": {
          "title": "VAEDecode"
        }
      },
      "37": {
        "inputs": {
          "filename": "qwen_image_edit_2509_fp8_e4m3fn.safetensors"
        },
        "class_type": "UNETLoader",
        "_meta": {
          "title": "UNETLoader"
        }
      },
      "38": {
        "inputs": {
          "filename": "qwen_2.5_vl_7b_fp8_scaled.safetensors"
        },
        "class_type": "CLIPLoader",
        "_meta": {
          "title": "CLIPLoader"
        }
      },
      "39": {
        "inputs": {
          "filename": "qwen_image_vae.safetensors"
        },
        "class_type": "VAELoader",
        "_meta": {
          "title": "VAELoader"
        }
      },
      "60": {
        "inputs": {
          "filename_prefix": "ComfyUI",
          "images": [
            "8",
            0
          ]
        },
        "class_type": "SaveImage",
        "_meta": {
          "title": "SaveImage"
        }
      },
      "66": {
        "inputs": {
          "value": 3,
          "model": [
            "440",
            0
          ]
        },
        "class_type": "ModelSamplingAuraFlow",
        "_meta": {
          "title": "ModelSamplingAuraFlow"
        }
      },
      "75": {
        "inputs": {
          "value": 1,
          "model": [
            "66",
            0
          ]
        },
        "class_type": "CFGNorm",
        "_meta": {
          "title": "CFGNorm"
        }
      },
      "78": {
        "inputs": {
          "image": "image_qwen_image_edit_2509_input_image.png"
        },
        "class_type": "LoadImage",
        "_meta": {
          "title": "LoadImage"
        }
      },
      "88": {
        "inputs": {
          "pixels": [
            "390",
            0
          ],
          "vae": [
            "39",
            0
          ]
        },
        "class_type": "VAEEncode",
        "_meta": {
          "title": "VAEEncode"
        }
      },
      "110": {
        "inputs": {
          "text": "",
          "clip": [
            "38",
            0
          ],
          "vae": [
            "39",
            0
          ],
          "image1": [
            "390",
            0
          ]
        },
        "class_type": "TextEncodeQwenImageEditPlus",
        "_meta": {
          "title": "TextEncodeQwenImageEditPlus"
        }
      },
      "111": {
        "inputs": {
          "text": "beautiful landscape, mountains, sunset, dramatic sky, cinematic photography",
          "clip": [
            "440",
            1
          ],
          "vae": [
            "39",
            0
          ],
          "image1": [
            "390",
            0
          ]
        },
        "class_type": "TextEncodeQwenImageEditPlus",
        "_meta": {
          "title": "TextEncodeQwenImageEditPlus"
        }
      },
      "390": {
        "inputs": {
          "image": [
            "78",
            0
          ]
        },
        "class_type": "FluxKontextImageScale",
        "_meta": {
          "title": "FluxKontextImageScale"
        }
      },
      "440": {
        "inputs": {
          "lora_name": "QWEN_EDIT_Unchained-XXX.safetensors",
          "strength_model": 0.15,
          "strength_clip": 1,
          "model": [
            "37",
            0
          ],
          "clip": [
            "38",
            0
          ]
        },
        "class_type": "LoraLoader",
        "_meta": {
          "title": "LoraLoader"
        }
      }
    }
  }
}